# Responsible AI Workshop - Responsible AI journey

This module contains a guide and a companion presentation that discuss the ethical underpinning of any journey towards responsible AI (RAI), and share Microsoft learning in such an ongoing journey.

Responsible AI is still an underrated subject among data scientists, AI engineers, and other AI practitioners more broadly, and today there is a huge gap between principles and tangible actions when it comes in their day-to-day development lifecycle to implement (more) responsible (non-generative, a.k.a. traditional, vs. generative) AI systems: the so-called "Responsible AI Gap".

Responsible AI (RAI) begins with the decision to intentionally design, build, and use AI in a way that honors a broad responsibility to people, organizations, and society. And thus RAI describes efforts to address technology from a sociotechnical perspective, recognizing the societal impact of technical systems. It's a set of steps we as a whole take to make sure that AI systems are safe, secure, and trustworthy. It is a culture and a everyday practice.

As such, in terms of learning objectives, the guide [Establishing your own responsible AI journey for your (non-generative vs. generative) AI-powered solutions](https://github.com/microsoft/responsible-ai-workshop/blob/main/responsible-ai-journey/docs/establishing-your-own-responsible-ai-journey.docx) is intended to share and comment from the intended audience's perspective an [ongoing journey towards responsible AI (RAI)](https://aka.ms/RAI), starting from defining core principles from which this effort is deeply anchored, to the translation of these principles into a [set of practices (along with tools)](https://aka.ms/RAI) to adopt, enforce, and evolve company-wide with respect to an end-to-end lifecycle for the design, the development, the deployment, and the monitoring of these (non-generative vs. generative) AI systems. 

The companion eponym presentation [Establishing your own responsible AI journey for your (non-generative vs. generative) AI-powered solutions](https://github.com/microsoft/responsible-ai-workshop/blob/main/responsible-ai-journey/ppts/establishing-your-own-responsible-ai-journey.pptx) provides a ready-to-use fully annotated content to organize a dedicated session to, once completed:
* Understand the ethical implications of designing, developing, deploying, and using AI.
* Comprehend what responsible AI means and why it is important in terms of guiding principles.
* Learn from Microsoft's approach to responsible AI - our journey, our principles, our standards, and our safeguards (see **References** below).
* Identify Microsoft's responsible AI tools and toolkits to help operationalize responsible AI.

Eventually, the [case study "Hospital Employee and Resource Optimization System" (HEROS)](ttps://github.com/microsoft/responsible-ai-workshop/blob/main/responsible-ai-journey/hands-on-tutorials/HEROS-case-study.pptx) allows to (optionally) conduct (in a group) a responsible AI impact assessment in a guided manner with brainstorming activities. 

Impact assessments (see **References** below) have proven valuable at Microsoft to ensure that teams thoroughly explore the impact of their AI system - including stakeholders, expected benefits, and potential disadvantages - from the very earliest stages of design. Stakeholder analysis brings these to light and allows teams to examine the impact the system may have on them. Questions related to the objectives of the standard help identify potential harm. As such, the impact assessment  is an evolving document, and the process of conducting an impact assessment is highly iterative. You can revisit the impact assessment as you deepen your understanding of the challenges of responsible AI within the project.

As such, one should also note that this module might be introduced by the following [Microsoft Learn](https://docs.microsoft.com/en-us/learn/) learning paths:
* [Discover ways to foster an AI-ready culture in your business](https://docs.microsoft.com/en-us/learn/paths/foster-ai-ready-culture/).
* [Identify principles and practices for responsible AI](https://docs.microsoft.com/en-us/learn/paths/responsible-ai-business-principles/).
* [Identify guiding principles for responsible AI in government](https://docs.microsoft.com/en-us/learn/paths/responsible-ai-government-principles/).

## References

From holistically transforming industries to addressing critical issues facing humanity, (Generative) AI is already solving some of our most complex challenges and redefining how humans and technology interact. 

You can read the publicly shared [Microsoft Responsible AI Standard](https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-Responsible-AI-Standard-v2-General-Requirements-3.pdf), i.e., a framework to guide how Microsoft build AI systems. It is an important step in our journey to develop better, more trustworthy AI systems. We are releasing our latest Responsible AI Standard to share what we have learned, invite feedback from others, and contribute to the discussion about building better norms and practices around AI. 

For those wanting to dig into our approach further, we have also made available some key resources that support the Responsible AI Standard: notably our [Impact Assessment template](https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Template.pdf) and [guide](https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Guide.pdf). Impact Assessments have proven valuable at Microsoft to ensure teams explore the impact of their AI system – including its stakeholders, intended benefits, and potential harms – in depth at the earliest design stages. 

You might also consider the following resources:
* [The A to Z of responsible AI](https://www.linkedin.com/pulse/z-responsible-ai-microsoft-on-the-issues)
* [What is Microsoft's approach to AI?](https://news.microsoft.com/source/features/ai/microsoft-approach-to-ai/)
* [Microsoft's framework for building AI systems responsibly](https://blogs.microsoft.com/on-the-issues/2022/06/21/microsofts-framework-for-building-ai-systems-responsibly/)
* [Microsoft Responsible AI Transparency Report](https://aka.ms/RAITransparencyReport2024)

## Additional resources

In addition, you can also visit our [Responsible AI resource center](https://www.microsoft.com/en-us/ai/responsible-ai) where you can find access to tools, guidelines, and additional resources that will help you create a (more) Responsible AI solution:
* [Responsible Use of Technology: The Microsoft Case Study](https://www3.weforum.org/docs/WEF_Responsible_Use_of_Technology_2021.pdf)
* [Put responsible AI into practice webinar](https://info.microsoft.com/ww-put-responsible-ai-into-practice-On-Demand-Registration.html) (On Demand).
* [Ten guidelines for product leaders to implement AI responsibly](https://aka.ms/RAITenGuidelines).
* [Establish a responsible AI strategy](https://aka.ms/AIBS).
* [Design, build, and manage your AI-powered solution](http://aka.ms/RAIresources)