# Responsible AI Workshop - Responsible AI journey

This module contains a guide and a companion presentation that discuss the ethical underpinning of any journey towards Responsible AI (RAI), and share Microsoft learning in such an ongoing journey.

Responsible AI is still an underrated subject among data scientists, AI engineers, and other AI practitioners more broadly, and today there is a huge gap between principles and tangible actions when it comes in their day-to-day development lifecycle to implement (more) responsible (non-Generative vs. Generative) AI systems: the so-called "Responsible AI Gap".

Responsible AI (RAI) begins with the decision to intentionally design, build, and use AI in a way that honors a broad responsibility to people, organizations, and society. And thus RAI describes efforts to address technology from a sociotechnical perspective, recognizing the societal impact of technical systems. It's a set of steps we as a whole take to make sure that AI systems are safe, secure, and trustworthy. It is a culture and a everyday practice.

As such, in terms of learning objectives, the guide [Establishing your own Responsible AI journey for your (non-Generative vs. Generative) AI-powered solutions](https://github.com/microsoft/responsible-ai-workshop/blob/main/responsable-ai-journey/docs/establishing-your-own-responsible-ai-journey.docx) is intended to share and comment from the intended audience's perspective an [ongoing journey towards Responsible AI (RAI)](https://aka.ms/RAI), starting from defining core principles from which this effort is deeply anchored, to the translation of these principles into a [set of practices (along with tools)](https://aka.ms/RAI) to adopt, enforce, and evolve company-wide with respect to an end-to-end lifecycle for the design, the development, the deployment, and the monitoring of these (non-Generative vs. Generative) AI systems. 

The companion eponym presentation [Establishing your own Responsible AI journey for your (non-Generative vs. Generative) AI-powered solutions](https://github.com/microsoft/responsible-ai-workshop/blob/main/responsable-ai-journey/ppts/establishing-your-own-responsible-ai-journey.pptx) provides a ready-to-use fully annotated content to organize a dedicated session to, once completed:
* Understand the ethical implications of designing, developing, deploying, and using AI.
* Comprehend what responsible AI means and why it is important in terms of guiding principles.
* Learn from Microsoft's approach to responsible AI - our journey, our principles, our standards, and our safeguards.
* Identify Microsoft's responsible AI tools and toolkits to help operationalize responsible AI.

Eventually, the [case study "Hospital Employee and Resource Optimization System" (HEROS)](ttps://github.com/microsoft/responsible-ai-workshop/blob/main/responsable-ai-journey/hands-on-tutorials/HEROS-case-study.pptx) allows to (optionally) conduct (in a group) a responsible AI impact assessment in a guided manner with brainstorming activities. 

Impact assessments have proven valuable at Microsoft to ensure that teams thoroughly explore the impact of their AI system - including stakeholders, expected benefits, and potential disadvantages - from the very earliest stages of design. Stakeholder analysis brings these to light and allows teams to examine the impact the system may have on them. Questions related to the objectives of the standard help identify potential harm. As such, the impact assessment  is an evolving document, and the process of conducting an impact assessment is highly iterative. You can revisit the impact assessment as you deepen your understanding of the challenges of responsible AI within the project.

## References
* [The A to Z of responsible AI](https://www.linkedin.com/pulse/z-responsible-ai-microsoft-on-the-issues)
* [What is Microsoft's Approach to AI?](https://news.microsoft.com/source/features/ai/microsoft-approach-to-ai/)
* [Microsoft's framework for building AI systems responsibly](https://blogs.microsoft.com/on-the-issues/2022/06/21/microsofts-framework-for-building-ai-systems-responsibly/)
* [Microsoft Responsible AI Transparency Report](https://aka.ms/RAITransparencyReport2024)

## Additional references
* [Responsible Use of Technology: The Microsoft Case Study](https://www3.weforum.org/docs/WEF_Responsible_Use_of_Technology_2021.pdf)