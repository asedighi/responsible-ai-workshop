{
  "answer": "Microsoft is involved in Responsible AI through their development of the Microsoft Responsible AI Standard, which is a set of guidelines for product development requirements for responsible AI. They have released a second version of the standard to share what they have learned, invite feedback from others, and contribute to the discussion about building better norms and practices around AI. Microsoft acknowledges that their standard is just one step in their responsible AI journey and acknowledge the need for collaboration between industry, academia, civil society, and government in advancing the state-of-the-art and learning from one another.",
  "context": [
    "Preview  – Microsoft Responsible AI Standar d v2 – Introduction  \n \n1 \n \n Microsoft \nResponsible AI \nStandard , v2 \n \nGENERAL REQUIREMENTS  \n \n \nFOR EXTERNAL RELEASE  \n \nJune 2022  \n \n \n  \n \n Microsoft Responsible AI Standard v2  \n \n2  \nIndex  \n \n \n \n \n \nAbout this release  ................................ ................................ ................................ ................................ ................................ ................................ ....... 3 \nAccountability Goals  ................................ ................................ ................................ ................................ ................................ ................................ .. 4 \nTransparency Goals  ................................ ................................ ................................ ................................ ................................ ................................ .... 9 \nFairness Goals  ................................ ................................ ......",
    "e embarked on our effort to operationalize Microsoft’s six AI principles, we knew there was a policy \ngap. Laws and norms had not caught up with AI’s unique risks or society’s needs. Yet, our product development \nteams needed concrete and actionable guidance as to what our principles meant and how they could uphold \nthem . We leveraged the expertise on our research, policy, and engineering teams to develop guidance on how  \nto fill that gap.  \n \nThe Responsible AI Standard is the product of a multi -year effort  to define product development requirements \nfor responsible AI.  We are making available th is second version of the Responsible AI Standard to share what  \nwe have learned, invite feedback from others,  and contribute to the discussion  about building better norms  \nand practices around AI . \n \nWhile our Standard is an important step in Microsoft’s responsible AI journey, it is just one step. As we make \nprogress with implementation,  we expect to encounter challenges that require us to pause, reflec",
    "f Sensitive Uses , with the Office of Responsible AI, to \ndevelop a plan detailing how the g ap will be managed until it can be closed. Document that plan.   \n \nTools and practices  \nRecommendation A 5.3.1 Follow the Guidelines for Human -AI Interaction  when designing the system.  \nRecommendation A 5.4.1 Assign user researchers to design these evaluations.  Microsoft Responsible AI Standard v2  \n \n9  \nTransparency  Goals  \nGoal T 1: System intelligibility for decision making  \nMicrosoft AI systems that inform decision making by or about people are designed to support stakeholder needs for \nintelligibility of system behavior.  \nApplies to: All AI systems  when the intended use of the generated outputs is to inform decision making by  or \nabout people.  \n \n Requirements  \nT1.1 Identify:  \n1) stakeholders who will use the outputs of the system to make decisions, and  \n2) stakeholders who are subject to decisions informed by the system.  \nDocument these stakeholders using the Impact Assessment template . \nTags: ",
    " expect to encounter challenges that require us to pause, reflect, and adjust. \nOur Standard will remain a living document, evolving to address new research, technologies, laws, and \nlearnings from within and outside the company.  \n \nThere is a rich and active global dialog about how to create principled and actionable norms to ensure \norganizations develop and deploy AI responsibly. We have benefited from this discussion and will continue to \ncontribute to it. We believe that industry, academia, civil soci ety, and government need to collaborate to \nadvance the state -of-the-art and learn from one another. Together, we  need to answer open research \nquestions, close  measurement gaps, and design  new practices, patterns, resources, and tools . \n \nAs we continue our journey, we welcome feedback on our approach and insights on other ways forward : \nhttps://aka.ms/ResponsibleAIQuestions  \n \n \n \n \n \n \n \n \n \n \n Microsoft Responsible AI Standard v2  \n \n4 Accountability  Goals  \nGoal A1: Impact  assessment  \nMicros",
    "n be closed. Document that plan.  Microsoft Responsible AI Standard v2  \n \n10 Tools and practices  \nRecommendation T 1.2.1 Follow the Guidelines for Human -AI Interaction when designing the system.  \n \nRecommendation  T1.2.2 Use one or more techniques available as part of the Interpret ML toolkit to understand \nthe impact of features on system behavior. This may help stakeholders who need to understand model predicti ons. \nRecommendation  T1.3.1 Assign user researchers to define, design, and prioritize evaluations in appropriately \nrealistic contexts  of use .  \n Microsoft Responsible AI Standard v2  \n \n11 Goal T2: Communication to stakeholders   \nMicrosoft provides information about the capabilities and limitations of our AI systems to support stakeholders in \nmaking informed choices about those systems.   \nApplies to:  All AI systems . \n \n  Requirements  \nT2.1 Identify : \n1) stakeholders who make decisions about whether to employ a system for particular tasks, and  \n2) stakeholders who develop or deploy sys"
  ],
  "groundedness": 10.0
}