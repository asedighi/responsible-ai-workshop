{
  "answer": "The RAI Impact Assessment at Microsoft refers to the process of assessing the impact of AI systems on people, organizations, and society early in the system's development. This assessment is documented using a template provided by the Office of Responsible AI and reviewed with the reviewers identified according to the organization's compliance process before development starts. The Impact Assessment is also updated and reviewed at least annually and before advancing to a new release stage. It is one of the requirements for Goal A1 - Impact Assessment in the Microsoft Responsible AI Standard v2.",
  "context": [
    " \n4 Accountability  Goals  \nGoal A1: Impact  assessment  \nMicrosoft AI systems are assessed using Impact Assessments.   \nApplies to:  All AI systems . \nRequirements   \nA1.1  Assess the impact of the system on people, organizations, and society by completing an Impact Assessment  \nearly in the system’s development, typically when defining the product vision and requirements. Document the \neffort using the Impact Assessment template  provided by the Office of Responsible AI . \nTags:  Impact Assessment . \nA1.2  Review the completed Impact Assessment  with the reviewers identified according to your organization’s \ncompliance process before development starts . Secure all required approvals from those reviewers.  \nTags:  Impact Assessment . \nA1.3  Update and r eview the Impact Assessment  at least annually , when new intended uses  are added,  and before \nadvancing to a new release stage.    \nTags:  Impact Assessment . \n \n \n \n \n \n \n \n \n \n  Microsoft Responsible AI Standard v2  \n \n5 Goal A2: Oversight of significan",
    "esponsible AI Standard v2  \n \n5 Goal A2: Oversight of significant adverse impacts  \nMicrosoft AI systems are reviewed to identify systems that may have a significant adverse impact on people, \norganizations, and society, and additional oversight and requirements are applied to those systems.   \nApplies to:  All AI systems . \nRequirements  \nA2.1  Review defined Restricted Uses  to determine whether the system meets the definition of any Restricted Use . \nIf it does , document this in the Impact Assessment , and follow the requirements for the  Restricted Use . \nTags:  Impact Assessment.  \nA2.2  Answer prompts in the Impact Assessment template  to determine whether the system meets the definition of \na Sensitive Use . If it does, report it to the Office of Responsible AI, and follow any additional requirements resulting \nfrom a Sensitive Uses review.  \nTags:  Impact Assessment.  \nA2.3  Review your systems at least annually against the definitions for Sensitive Uses and  Restricted Uses. If there \nare systems th",
    "reassessment of intended uses and updated documentation is required.  \nTags:  Ongoing Evaluation Checkpoint . \nRS1.9  Provide documentation to customers and potential customers of the system that includes the outputs of \nrequirements RS1. 2, RS1.7 and RS1.8, and any unsupported uses defined i n the Impact Assessment and in RS1.8. \nWhen the system is a platform service made available to external customers or partners, include this information in \nthe required Transparency Note.  \nTags:  Impact Assessment , Transparency Note . Microsoft Responsible AI Standard v2  \n \n22  \nTools and practices  \nRecommendation RS1. 1.1 Interview safety experts and review relevant literature for domains where the system \nmay impact the safety of people.  \nRecommendation RS1. 4.1 Interview customers to understand operational factors and their variations.  \n \n  Microsoft Responsible AI Standard v2  \n \n23 Goal RS2:  Failures and remediations  \nMicrosoft AI systems are designed to minimize the time to remediation of predictable or kno",
    "f Sensitive Uses , with the Office of Responsible AI, to \ndevelop a plan detailing how the g ap will be managed until it can be closed. Document that plan.   \n \nTools and practices  \nRecommendation A 5.3.1 Follow the Guidelines for Human -AI Interaction  when designing the system.  \nRecommendation A 5.4.1 Assign user researchers to design these evaluations.  Microsoft Responsible AI Standard v2  \n \n9  \nTransparency  Goals  \nGoal T 1: System intelligibility for decision making  \nMicrosoft AI systems that inform decision making by or about people are designed to support stakeholder needs for \nintelligibility of system behavior.  \nApplies to: All AI systems  when the intended use of the generated outputs is to inform decision making by  or \nabout people.  \n \n Requirements  \nT1.1 Identify:  \n1) stakeholders who will use the outputs of the system to make decisions, and  \n2) stakeholders who are subject to decisions informed by the system.  \nDocument these stakeholders using the Impact Assessment template . \nTags: ",
    "or Sensitive Uses and  Restricted Uses. If there \nare systems that meet the criteria for Sensitive Uses, report them  to the Office of Responsible AI . If there are \nsystems that meet the criteria for Restricted Uses, notify the Office of Responsible AI . \n Microsoft Responsible AI Standard v2  \n \n6 Goal A3: Fit for purpose  \nMicrosoft AI systems are fit for purpose in the sense that they provide valid solutions for the problems they are \ndesigned to solve . \nApplies to: All AI systems . \nRequirements  \nA3.1 Document in the Impact Assessment  how the system’s use will solve the problem posed by each  intended use , \nrecognizing that there may be multiple valid ways in which to solve the problem.  \nTags:  Impact Assessment . \nA3.2 Define and document for each model in the AI system:  \n1) the model’s proposed  inputs and how well they represent the concepts they are intended to represent ; include \nanalysis of the limitations of this representation , \n2) the model’s proposed  output  and how well it represents "
  ],
  "groundedness": 10.0
}